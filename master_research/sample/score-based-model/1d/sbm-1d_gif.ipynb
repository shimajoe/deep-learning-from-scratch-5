{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75cacdb",
   "metadata": {},
   "source": [
    "# Score Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67896de",
   "metadata": {},
   "source": [
    "## ノイズスケジュールの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed90c84",
   "metadata": {},
   "source": [
    "線形にノイズの分散が増加するシンプルなスケジュールを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938c937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7729ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "timesteps = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "alphas = 1. - betas\n",
    "alpha_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "def noise_schedule(t):\n",
    "    sqrt_alpha_cumprod_t = torch.sqrt(alpha_cumprod[t])\n",
    "    sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - alpha_cumprod[t])\n",
    "    return sqrt_alpha_cumprod_t, sqrt_one_minus_alpha_cumprod_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc1830",
   "metadata": {},
   "source": [
    "## スコアネットワークの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481c5d1",
   "metadata": {},
   "source": [
    "簡単なMLP（多層パーセプトロン）をスコアネットワークとして使用します。入力はノイズが加えられたデータとタイムステップの埋め込みです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d694b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, time_embed_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim + time_embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.time_embed = nn.Linear(1, time_embed_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # タイムステップを埋め込み\n",
    "        t_embed = self.time_embed(t[:, None].float() / timesteps)\n",
    "        h = torch.cat([x, t_embed], dim=1)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc3(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422794b",
   "metadata": {},
   "source": [
    "## 損失関数の定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc583b25",
   "metadata": {},
   "source": [
    "ノイズを加えたデータから推定されたスコアと、真のノイズの負の値を近づける損失関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70ea5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x_0, t):\n",
    "    sqrt_alpha_cumprod_t, sqrt_one_minus_alpha_cumprod_t = noise_schedule(t)\n",
    "    noise = torch.randn_like(x_0)\n",
    "    # ノイズを加えたデータ\n",
    "    x_t = sqrt_alpha_cumprod_t[:, None] * x_0 + sqrt_one_minus_alpha_cumprod_t[:, None] * noise\n",
    "    # スコアネットワークによるスコアの推定\n",
    "    predicted_score = model(x_t, t)\n",
    "    # 真のスコアはノイズの負の値に比例する（重み付けは省略）\n",
    "    target_score = -noise\n",
    "    loss = F.mse_loss(predicted_score, target_score)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb79643",
   "metadata": {},
   "source": [
    "## 学習ループ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930c116",
   "metadata": {},
   "source": [
    "簡単な学習ループの例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67f85c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joichiro Shimada\\AppData\\Local\\Temp\\ipykernel_10420\\2841673527.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# データ生成 (例として1次元のガウス分布からのサンプル)\n",
    "def generate_data(n_samples=500):\n",
    "    return torch.randn(n_samples, 1) * 2 + 5\n",
    "\n",
    "data = generate_data(500)\n",
    "dataset = TensorDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# データの可視化\n",
    "plt.hist(data.numpy(), bins=30, density=True)\n",
    "plt.title(\"Data Distribution\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d0d2d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.3763\n",
      "Epoch [200/1000], Loss: 0.2844\n",
      "Epoch [300/1000], Loss: 0.3956\n",
      "Epoch [400/1000], Loss: 0.4622\n",
      "Epoch [500/1000], Loss: 0.3176\n",
      "Epoch [600/1000], Loss: 0.4808\n",
      "Epoch [700/1000], Loss: 0.4839\n",
      "Epoch [800/1000], Loss: 0.5504\n",
      "Epoch [900/1000], Loss: 0.4184\n",
      "Epoch [1000/1000], Loss: 0.3083\n"
     ]
    }
   ],
   "source": [
    "# モデルとオプティマイザの初期化\n",
    "input_dim = 1\n",
    "hidden_dim = 128\n",
    "time_embed_dim = 32\n",
    "model = ScoreNet(input_dim, hidden_dim, time_embed_dim)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        x_0 = batch[0]\n",
    "        t = torch.randint(0, timesteps, (x_0.shape[0],))\n",
    "        loss = loss_fn(model, x_0, t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3259b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_and_record(model, n_samples, timesteps, alphas, alpha_cumprod, betas, device=\"cpu\"):\n",
    "    x_t = torch.randn(n_samples, 1).to(device)\n",
    "    intermediate_frames = []\n",
    "    num_steps = timesteps // 20 # 例えば20ステップごとに保存\n",
    "    steps_to_save = np.linspace(timesteps - 1, 0, num_steps, dtype=int)\n",
    "\n",
    "    for i in reversed(range(timesteps)):\n",
    "        t = torch.ones(n_samples, dtype=torch.long).to(device) * i\n",
    "        sqrt_alpha_t = torch.sqrt(alphas[i])\n",
    "        beta_t = betas[i]\n",
    "        score_t = model(x_t, t)\n",
    "        x_t = (1 / sqrt_alpha_t) * (x_t - (beta_t / torch.sqrt(1 - alpha_cumprod[i])) * score_t)\n",
    "        if i > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "            posterior_variance = beta_t\n",
    "            x_t = x_t + torch.sqrt(posterior_variance) * noise\n",
    "\n",
    "        if i in steps_to_save:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.hist(x_t.cpu().numpy(), bins=30, alpha=0.7)\n",
    "            ax.set_title(f\"Timestep: {i}\")\n",
    "            fig.canvas.draw()\n",
    "            # Use buffer_rgba and convert RGBA to RGB\n",
    "            image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "            w, h = fig.canvas.get_width_height()\n",
    "            image = image.reshape((h, w, 4))[..., :3]  # Drop alpha channel\n",
    "            intermediate_frames.append(image)\n",
    "            plt.close()\n",
    "\n",
    "    return x_t.cpu().numpy(), intermediate_frames\n",
    "\n",
    "# サンプリングの実行と結果の可視化\n",
    "model.eval()\n",
    "sampled_data, frames = sample_and_record(model, n_samples=500, timesteps=timesteps, alphas=alphas, alpha_cumprod=alpha_cumprod, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c831f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved to: sampling_process_1d.gif\n"
     ]
    }
   ],
   "source": [
    "# GIFとして保存\n",
    "output_gif_path = \"sampling_process_1d.gif\"\n",
    "imageio.mimsave(output_gif_path, frames, duration=0.1) # durationはフレーム間の時間 (秒)\n",
    "print(f\"GIF saved to: {output_gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb2ee2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joichiro Shimada\\AppData\\Local\\Temp\\ipykernel_10420\\413794382.py:7: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# 必要に応じて最終的なサンプルの可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(generate_data(1000).numpy(), bins=30, alpha=0.5, label='Original Data')\n",
    "plt.hist(sampled_data, bins=30, alpha=0.5, label='Sampled Data')\n",
    "plt.legend()\n",
    "plt.title('Final Sampled Data')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
