{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拡散モデル: GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "np.random.seed(42) # 乱数生成用のシードを設定\n",
    "ite = 1 # 乱数生成の回数\n",
    "\n",
    "random_seed = np.random.randint(0, 10000, ite)  # ランダムな整数値をシード値として取得.例えば 0 〜 9999 の間の整数をite個生成\n",
    "print(\"random_seed\", random_seed) # 乱数シード値の確認\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正弦波位置エンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 時間埋め込み（正弦波位置エンコーディング）---\n",
    "# output_dim が偶数であることを前提とするか、奇数にも対応できるよう調整\n",
    "def pos_encoding(timesteps, output_dim, device='cpu'):\n",
    "    # timestepsをfloat型かつ2次元テンソル (batch_size, 1) に変換\n",
    "    # dtypeを明示的に指定\n",
    "    position = timesteps.unsqueeze(1).float().to(device)\n",
    "\n",
    "    # div_term の計算 (output_dim が奇数の場合を考慮し、output_dim // 2 とする)\n",
    "    # output_dim が奇数の場合、最後の次元は0でパディングするか、または無視される\n",
    "    div_term = torch.exp(torch.arange(0, output_dim, 2, device=device, dtype=torch.float32) * (-np.log(10000.0) / output_dim))\n",
    "\n",
    "    # sin と cos の計算\n",
    "    sin_vals = torch.sin(position * div_term)\n",
    "    cos_vals = torch.cos(position * div_term)\n",
    "\n",
    "    # 結合し、output_dim に合うように調整\n",
    "    sinusoid = torch.cat([sin_vals, cos_vals], dim=1)\n",
    "\n",
    "    # もし output_dim が奇数で、かつその次元が重要なら調整が必要\n",
    "    # 例えば、output_dim が17なら、sinusoid は16次元になる。\n",
    "    # 完全に output_dim と同じ次元にするならパディングするか、output_dim は偶数に固定すべき\n",
    "    if sinusoid.shape[1] < output_dim:\n",
    "        # 残りの次元を0でパディング (例: output_dim=17 の場合、1次元足りない)\n",
    "        padding = torch.zeros(sinusoid.shape[0], output_dim - sinusoid.shape[1], device=device, dtype=torch.float32)\n",
    "        sinusoid = torch.cat([sinusoid, padding], dim=1)\n",
    "    elif sinusoid.shape[1] > output_dim:\n",
    "        # 偶数で初期化したが、output_dimが小さい場合 (例: output_dim=16だが、計算上18になってしまった場合)\n",
    "        # これは通常発生しないが、安全のため\n",
    "        sinusoid = sinusoid[:, :output_dim]\n",
    "\n",
    "    return sinusoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拡散モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 拡散モデル ---\n",
    "class DiffusionModel(nn.Module):\n",
    "    # input_data_dim を引数として追加\n",
    "    def __init__(self, input_data_dim, time_embed_dim=16, hidden_dim=64, dropout_rate=0.1, activation='leaky_relu'):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.time_embed_dim = time_embed_dim\n",
    "        self.input_data_dim = input_data_dim # 入力データの次元を保持\n",
    "\n",
    "        # 活性化関数の選択\n",
    "        if activation == 'leaky_relu':\n",
    "            self.activation_fn = nn.LeakyReLU()\n",
    "        elif activation == 'elu':\n",
    "            self.activation_fn = nn.ELU()\n",
    "        else: # default to ReLU\n",
    "            self.activation_fn = nn.ReLU()\n",
    "\n",
    "        # 各層にBatch NormalizationとDropoutを追加\n",
    "        # fc1の入力次元を input_data_dim + time_embed_dim に変更\n",
    "        self.fc1 = nn.Linear(self.input_data_dim + time_embed_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim) # BatchNorm1d は特徴量次元に適用\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 最終出力層の次元を input_data_dim に変更\n",
    "        self.fc3 = nn.Linear(hidden_dim, self.input_data_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # time_embed_dim は self.time_embed_dim を使用\n",
    "        t_embed = pos_encoding(t, self.time_embed_dim, x.device)\n",
    "\n",
    "        x_t = torch.cat([x, t_embed], dim=-1)\n",
    "\n",
    "        # Batch Normalization -> Activation -> Dropout の順\n",
    "        x_t = self.fc1(x_t)\n",
    "        x_t = self.bn1(x_t)\n",
    "        x_t = self.activation_fn(x_t)\n",
    "        x_t = self.dropout1(x_t)\n",
    "\n",
    "        x_t = self.fc2(x_t)\n",
    "        x_t = self.bn2(x_t)\n",
    "        x_t = self.activation_fn(x_t)\n",
    "        x_t = self.dropout2(x_t)\n",
    "\n",
    "        return self.fc3(x_t)\n",
    "\n",
    "# --- 拡散プロセス ---\n",
    "class Diffuser:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02, device='cpu'):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.device = device\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def add_noise(self, x_0, t):\n",
    "        # t_idx は (batch_size,) のテンソルを想定\n",
    "        # alpha_bars から適切な alpha_bar を取得するために gather を使用\n",
    "        t_idx = t - 1 # alphas[0] is for t=1\n",
    "        alpha_bar = self.alpha_bars.gather(0, t_idx).view(-1, 1) # (N, 1)\n",
    "\n",
    "        noise = torch.randn_like(x_0, device=self.device)\n",
    "        x_t = torch.sqrt(alpha_bar) * x_0 + torch.sqrt(1 - alpha_bar) * noise\n",
    "        return x_t, noise\n",
    "\n",
    "    def denoise(self, model, x, t):\n",
    "        T = self.num_timesteps\n",
    "        # tがtensorの場合のassert\n",
    "        assert torch.all(t >= 1) and torch.all(t <= T)\n",
    "\n",
    "        t_idx = t - 1 # alphas[0] is for t=1\n",
    "\n",
    "        # alpha と alpha_bar も gather を使用\n",
    "        alpha = self.alphas.gather(0, t_idx).view(-1, 1)\n",
    "        alpha_bar = self.alpha_bars.gather(0, t_idx).view(-1, 1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            eps = model(x, t)\n",
    "\n",
    "        # DDPM論文のサンプリングステップの計算\n",
    "        # x_{t-1} の平均項\n",
    "        mu = (x - (1 - alpha) / torch.sqrt(1 - alpha_bar) * eps) / torch.sqrt(alpha)\n",
    "\n",
    "        # x_{t-1} の分散項 (標準偏差)\n",
    "        # DDPMでは、最終ステップ(t=1)以外はノイズを追加\n",
    "        # beta_t_tilde = (1 - alpha_bar_{t-1}) / (1 - alpha_bar_t) * beta_t\n",
    "        # 一般的にはベータの分散を用いることが多い\n",
    "        # 例えば、beta_t = self.betas[t_idx]\n",
    "        sigma = torch.sqrt(self.betas.gather(0, t_idx)).view(-1, 1) # sqrt(beta_t)\n",
    "\n",
    "        # t=1 の場合はノイズを加えない (x_0を生成する最終ステップ)\n",
    "        # tがtensorの場合の条件分岐\n",
    "        z = torch.randn_like(x, device=self.device)\n",
    "        z[t == 1] = 0 # t=1のバッチ要素のみzを0にする\n",
    "\n",
    "        x_prev = mu + sigma * z\n",
    "\n",
    "        return x_prev # x_{t-1} を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM学習データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_uncorrelated_gmm_2d_toy_dataset(num_total_samples=2000,\n",
    "                                            ratio_mode1=0.5, # モード1のデータが全体の何割を占めるか (0.0 ~ 1.0)\n",
    "                                            mu1=np.array([-3.0, -3.0]),\n",
    "                                            sigma1_diag=np.array([1.0, 1.0]), # 対角成分のみ指定\n",
    "                                            mu2=np.array([3.0, 3.0]),\n",
    "                                            sigma2_diag=np.array([1.0, 1.0]), # 対角成分のみ指定\n",
    "                                            random_seed=42):\n",
    "    \"\"\"\n",
    "    2つの無相関な2次元正規分布を組み合わせたガウス混合モデル (GMM) からトイデータセットを生成します。\n",
    "    各正規分布の比率を指定できます。\n",
    "\n",
    "    Args:\n",
    "        num_total_samples (int): 生成する総サンプル数。\n",
    "        ratio_mode1 (float): モード1 (1つ目の正規分布) のデータが全体の何割を占めるか (0.0 ~ 1.0)。\n",
    "                              モード2の比率は (1 - ratio_mode1) になります。\n",
    "        mu1 (np.ndarray): 1つ目の正規分布の平均ベクトル (2次元)。\n",
    "        sigma1_diag (np.ndarray): 1つ目の正規分布の共分散行列の対角成分 (2要素)。\n",
    "                                  非対角成分は0と仮定されます。\n",
    "        mu2 (np.ndarray): 2つ目の正規分布の平均ベクトル (2次元)。\n",
    "        sigma2_diag (np.ndarray): 2つ目の正規分布の共分散行列の対角成分 (2要素)。\n",
    "                                  非対角成分は0と仮定されます。\n",
    "        random_seed (int): 乱数生成のシード。\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 生成されたデータポイント (N x 2)。\n",
    "    \"\"\"\n",
    "    if not (0.0 <= ratio_mode1 <= 1.0):\n",
    "        raise ValueError(\"ratio_mode1 must be between 0.0 and 1.0\")\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # 各モードのサンプル数を計算\n",
    "    num_samples_mode1 = int(num_total_samples * ratio_mode1)\n",
    "    num_samples_mode2 = num_total_samples - num_samples_mode1 # 残りはモード2\n",
    "\n",
    "    # 共分散行列を作成 (対角成分のみ有効)\n",
    "    sigma1 = np.diag(sigma1_diag)\n",
    "    sigma2 = np.diag(sigma2_diag)\n",
    "\n",
    "    print(f\"Generating {num_total_samples} samples:\")\n",
    "    print(f\"  Mode 1 ({ratio_mode1*100:.1f}%): {num_samples_mode1} samples\")\n",
    "    print(f\"  Mode 2 ({(1-ratio_mode1)*100:.1f}%): {num_samples_mode2} samples\")\n",
    "\n",
    "    # 1つ目の正規分布からデータを生成\n",
    "    data_mode1 = np.random.multivariate_normal(mu1, sigma1, num_samples_mode1)\n",
    "\n",
    "    # 2つ目の正規分布からデータを生成\n",
    "    data_mode2 = np.random.multivariate_normal(mu2, sigma2, num_samples_mode2)\n",
    "\n",
    "    # 両方のデータを結合\n",
    "    dataset = np.vstack((data_mode1, data_mode2))\n",
    "\n",
    "    # データをシャッフル (モードの偏りをなくすため)\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def plot_2d_dataset(dataset, title=\"2D GMM Toy Dataset (Uncorrelated)\"):\n",
    "    \"\"\"\n",
    "    2次元データセットをプロットします。\n",
    "\n",
    "    Args:\n",
    "        dataset (np.ndarray): プロットするデータセット (N x 2)。\n",
    "        title (str): グラフのタイトル。\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(dataset[:, 0], dataset[:, 1], s=10, alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal') # x軸とy軸のスケールを合わせる\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例4: 比率30:70、円形クラスタ\n",
    "print(\"--- Example 4: 30:70 Ratio, Circular Clusters ---\")\n",
    "dataset4 = generate_uncorrelated_gmm_2d_toy_dataset(\n",
    "    num_total_samples=2000,\n",
    "    ratio_mode1=0.3,\n",
    "    mu1=np.array([-3.0, -3.0]),\n",
    "    sigma1_diag=np.array([1.0, 1.0]),\n",
    "    mu2=np.array([3.0, 3.0]),\n",
    "    sigma2_diag=np.array([1.0, 1.0])\n",
    ")\n",
    "plot_2d_dataset(dataset4, title=\"Uncorrelated GMM (30:70, Circular)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7:3混合正規分布の密度関数\n",
    "from matplotlib.pylab import multivariate_normal\n",
    "\n",
    "\n",
    "def gmm_density(x, mu1, sigma1_diag, mu2, sigma2_diag, ratio_mode1):\n",
    "    \"\"\"\n",
    "    2つの無相関な正規分布の混合密度関数を計算します。\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): 入力データポイント (N x 2)。\n",
    "        mu1 (np.ndarray): 1つ目の正規分布の平均ベクトル (2次元)。\n",
    "        sigma1_diag (np.ndarray): 1つ目の正規分布の共分散行列の対角成分 (2要素)。\n",
    "        mu2 (np.ndarray): 2つ目の正規分布の平均ベクトル (2次元)。\n",
    "        sigma2_diag (np.ndarray): 2つ目の正規分布の共分散行列の対角成分 (2要素)。\n",
    "        ratio_mode1 (float): モード1の比率。\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: 各データポイントに対する混合密度関数の値。\n",
    "    \"\"\"\n",
    "    # 共分散行列を作成\n",
    "    sigma1 = np.diag(sigma1_diag)\n",
    "    sigma2 = np.diag(sigma2_diag)\n",
    "\n",
    "    # 各モードの密度を計算\n",
    "    density_mode1 = multivariate_normal.pdf(x, mean=mu1, cov=sigma1)\n",
    "    density_mode2 = multivariate_normal.pdf(x, mean=mu2, cov=sigma2)\n",
    "\n",
    "    # 混合密度を計算\n",
    "    mixed_density = ratio_mode1 * density_mode1 + (1 - ratio_mode1) * density_mode2\n",
    "\n",
    "    return mixed_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = np.array([3.0, 3.0])\n",
    "mu2 = np.array([-3.0, -3.0])\n",
    "top_density = gmm_density(mu1, mu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カーネル密度推定(KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カーネル密度推定のための関数\n",
    "def plot_kde_2d(dataset, title=\"2D KDE Plot\"):\n",
    "    \"\"\"\n",
    "    2次元データセットのカーネル密度推定 (KDE) プロットを作成します。\n",
    "\n",
    "    Args:\n",
    "        dataset (np.ndarray): プロットするデータセット (N x 2)。\n",
    "        title (str): グラフのタイトル。\n",
    "    \"\"\"\n",
    "    from scipy.stats import gaussian_kde\n",
    "\n",
    "    # KDEを計算\n",
    "    kde = gaussian_kde(dataset.T)\n",
    "    x_min, x_max = dataset[:, 0].min(), dataset[:, 0].max()\n",
    "    y_min, y_max = dataset[:, 1].min(), dataset[:, 1].max()\n",
    "    \n",
    "    x_grid = np.linspace(x_min, x_max, 100)\n",
    "    y_grid = np.linspace(y_min, y_max, 100)\n",
    "    X, Y = np.meshgrid(x_grid, y_grid)\n",
    "    Z = kde(np.vstack([X.ravel(), Y.ravel()])).reshape(X.shape)\n",
    "\n",
    "    # プロット\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
    "    plt.colorbar(label='Density')\n",
    "    plt.scatter(dataset[:, 0], dataset[:, 1], s=10, alpha=0.5, color='white')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal') # x軸とy軸のスケールを合わせる\n",
    "    plt.show()\n",
    "# KDEプロットの例\n",
    "print(\"--- KDE Plot for Example 4 ---\")\n",
    "plot_kde_2d(dataset4, title=\"KDE Plot for Uncorrelated GMM (30:70, Circular)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "seed = 42 # 乱数シード値\n",
    "num_timesteps = 1000 # 拡散ステップ数\n",
    "epochs = 20          # 学習エポック数\n",
    "lr = 5e-3         # 学習率\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "time_embed_dim = 16\n",
    "input_data_dim = dataset4.shape[1] # データセットの次元数\n",
    "hidden_dim = 64 # 隠れ層の次元数\n",
    "model = DiffusionModel(input_data_dim=input_data_dim, time_embed_dim=time_embed_dim, hidden_dim=hidden_dim).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "diffuser = Diffuser(num_timesteps=num_timesteps, device=device)\n",
    "\n",
    "# 学習データ(ガウスノイズ)\n",
    "print(\"############################################\")\n",
    "start_time = time.time() # 計測開始\n",
    "# print(f\"Data_Set_{i+1}, Seed: {seed}\") # 開始の合図\n",
    "\n",
    "print(f\"拡散ステップ数: {num_timesteps}, 学習エポック数: {epochs}, 学習率: {lr}\")\n",
    "print(\"############################################\")\n",
    "np.random.seed(seed) # 取得した乱数を新しいシード値として設定\n",
    "data = dataset4 # 例4のデータセットを使用\n",
    "print(\"data\", len(data))\n",
    "batch_size = 64 # バッチサイズ\n",
    "# モデル学習に使う DataLoader も float32 のテンソルから作成\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# データの要約\n",
    "print(\"dataの平均ベクトル\", np.mean(data, axis=0)) # 平均ベクトル\n",
    "print(\"dataの分散共分散行列\", np.cov(data.T)) # 分散共分散行列\n",
    "print(\"dataの相関係数\", np.corrcoef(data.T)) # 相関係数\n",
    "\n",
    "# 学習\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0.0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        x = batch.to(device).float()\n",
    "        t = torch.randint(1, num_timesteps + 1, (len(x),), device=device)\n",
    "\n",
    "        x_noisy, noise = diffuser.add_noise(x, t)\n",
    "        x_noisy = x_noisy.float()\n",
    "        noise = noise.float()\n",
    "        noise_pred = model(x_noisy, t)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "    avg_loss = loss_sum / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    # 5の倍数エポックで損失を表示\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")\n",
    "print(\"学習終了\")\n",
    "end_time = time.time() # 計測終了\n",
    "print('\\n')\n",
    "print(f\"学習時間: {end_time - start_time:.2f}秒\")\n",
    "\n",
    "\n",
    "# 学習曲線のプロット\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Trained By data_by_seed_{}'.format(seed))\n",
    "plt.show()\n",
    "print('\\n')\n",
    "print(\"#\"*50)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプリングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# (前回のDiffuser, DiffusionModel, pos_encodingの定義がここにあると仮定)\n",
    "# Diffuserインスタンスを初期化 (num_timesteps を明示的に渡す)\n",
    "# モデルの初期化もここで行われると仮定\n",
    "# 例:\n",
    "# num_timesteps = 1000 # 定義が必要\n",
    "# diffuser = Diffuser(num_timesteps=num_timesteps, device=device)\n",
    "# model = DiffusionModel(time_embed_dim=16, hidden_dim=64, dropout_rate=0.1, activation='leaky_relu').to(device)\n",
    "# model.load_state_dict(torch.load('your_model_weights.pth')) # 学習済みモデルをロードする場合\n",
    "\n",
    "# 拡散モデルのサンプリング関数\n",
    "def generate_samples(model, diffuser_instance, n_samples=1000, n_batches=100, device='cpu'):\n",
    "    \"\"\"\n",
    "    学習済み拡散モデルを用いてサンプルを生成します。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 学習済みの拡散モデル（ノイズ予測器）。\n",
    "        diffuser_instance (Diffuser): 拡散プロセスを管理するDiffuserインスタンス。\n",
    "        n_samples (int): 各生成バッチで生成するサンプル数。\n",
    "        n_batches (int): 何回生成プロセスを繰り返すか（生成するデータセットの数）。\n",
    "        device (str): テンソルを配置するデバイス ('cuda' または 'cpu')。\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 生成されたサンプル。形状は (n_batches, n_samples, 2)。\n",
    "    \"\"\"\n",
    "    model.eval() # モデルを評価モードに設定\n",
    "    \n",
    "    new_sample_list = [] # 生成された各バッチのサンプルを格納するリスト\n",
    "    \n",
    "    # tqdm の記述をより明確に\n",
    "    print(f\"Generating {n_batches} batches, each with {n_samples} samples...\")\n",
    "    for _ in tqdm(range(n_batches), desc=\"Generating Samples\"):\n",
    "        # 各生成バッチで異なる初期ノイズから開始\n",
    "        # torch.manual_seed はここでは不要（異なるランダムノイズが欲しい場合）\n",
    "        samples = torch.randn((n_samples, 2), device=device) # x_T (完全なノイズ)\n",
    "\n",
    "        # 拡散ステップを逆に進める (T -> T-1 -> ... -> 1)\n",
    "        for t in range(diffuser_instance.num_timesteps, 0, -1):\n",
    "            # 現在の時刻情報をテンソルに変換\n",
    "            # t_tensorは、バッチ内の各サンプルに対して同じ時刻 't' を持つ\n",
    "            t_tensor = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "            \n",
    "            # ノイズ除去ステップ (x_t から x_{t-1} を計算)\n",
    "            # diffuser.denoise はモデルの評価モードとno_gradを自身で管理しないように変更済みと仮定\n",
    "            # generate_samples 関数が全体のno_gradを管理する\n",
    "            with torch.no_grad(): # 全体の生成プロセスを no_grad ブロックで囲む\n",
    "                samples = diffuser_instance.denoise(model, samples, t_tensor)\n",
    "            \n",
    "        # 最終的にデノイズされたサンプル (x_0) をリストに追加\n",
    "        new_sample_list.append(samples.cpu().numpy())\n",
    "        \n",
    "    return np.array(new_sample_list) # (n_batches, n_samples, 2) のNumPy配列\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- デバイスの設定 ---\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # # --- 拡散モデルとDiffuserのパラメータ設定 ---\n",
    "    # num_timesteps = 1000 \n",
    "    # beta_start = 0.0001\n",
    "    # beta_end = 0.02\n",
    "    # time_embed_dim = 16\n",
    "    # hidden_dim = 64\n",
    "    # dropout_rate = 0.1\n",
    "    # activation = 'leaky_relu'\n",
    "\n",
    "    # # --- Diffuserとモデルのインスタンス化 ---\n",
    "    # diffuser = Diffuser(num_timesteps=num_timesteps, beta_start=beta_start, beta_end=beta_end, device=device)\n",
    "    # model = DiffusionModel(time_embed_dim=time_embed_dim, hidden_dim=hidden_dim, \n",
    "    #                        dropout_rate=dropout_rate, activation=activation).to(device)\n",
    "\n",
    "    # --- (注意) ここに学習済みモデルのロード処理が入ります ---\n",
    "    # 例: model.load_state_dict(torch.load(\"path_to_your_trained_model.pth\"))\n",
    "    # ロードしない場合、モデルは初期状態なのでランダムなサンプルしか生成しません。\n",
    "    print(\"WARNING: Model is not loaded with trained weights. Generating random samples.\")\n",
    "\n",
    "    # --- サンプリングの実行 ---\n",
    "    generated_data = generate_samples(\n",
    "        model=model,\n",
    "        diffuser_instance=diffuser,\n",
    "        n_samples=2000,    # 1バッチあたりのサンプル数\n",
    "        n_batches=50,      # 生成するバッチ数\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(f\"Shape of generated_data: {generated_data.shape}\") # (n_batches, n_samples, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"generated_data.shape\", generated_data.shape)\n",
    "print(\"generated_data[0].shape\", generated_data[0].shape) # (1000, 2)\n",
    "print(\"generated_data.shape[0]\", generated_data.shape[0]) # バッチ数\n",
    "print(\"generated_data[0, :, 0].shape\", generated_data[0, :, 0].shape) # 2次元のサンプルデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  # 生成されたデータの一部を可視化（最初のバッチ）\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  if generated_data.shape[0] > 0:\n",
    "      plt.figure(figsize=(8, 6))\n",
    "      plt.scatter(generated_data[0, :, 0], generated_data[0, :, 1], s=10, alpha=0.7)\n",
    "      plt.title(\"Example of Generated Samples (First Batch)\")\n",
    "      plt.xlabel(\"Dimension 1\")\n",
    "      plt.ylabel(\"Dimension 2\")\n",
    "      plt.grid(True)\n",
    "      plt.axis('equal')\n",
    "      plt.show()\n",
    "\n",
    "      # 複数のバッチを可視化して多様性を確認\n",
    "      if generated_data.shape[0] > 1:\n",
    "          fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "          axes[0].scatter(generated_data[0, :, 0], generated_data[0, :, 1], s=10, alpha=0.7)\n",
    "          axes[0].set_title(\"Generated Batch 1\")\n",
    "          axes[0].set_xlabel(\"Dimension 1\")\n",
    "          axes[0].set_ylabel(\"Dimension 2\")\n",
    "          axes[0].set_aspect('equal', adjustable='box')\n",
    "          axes[0].grid(True)\n",
    "\n",
    "          axes[1].scatter(generated_data[1, :, 0], generated_data[1, :, 1], s=10, alpha=0.7)\n",
    "          axes[1].set_title(\"Generated Batch 2\")\n",
    "          axes[1].set_xlabel(\"Dimension 1\")\n",
    "          axes[1].set_ylabel(\"Dimension 2\")\n",
    "          axes[1].set_aspect('equal', adjustable='box')\n",
    "          axes[1].grid(True)\n",
    "          plt.tight_layout()\n",
    "          plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成したデータをKDEにより表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"generated_data[0].shape\", generated_data[0].shape) # (1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDEプロットの例\n",
    "print(\"--- KDE Plot for Generated Samples ---\")\n",
    "plot_kde_2d(generated_data[0], title=\"KDE Plot for Generated Samples (First Batch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最初のバッチでKDE→頂点の距離を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "kde_generated_data = gaussian_kde(generated_data[0].T)\n",
    "\n",
    "# --- 評価グリッドの定義 ---\n",
    "# generated_data[0] の範囲に基づいてグリッドを生成\n",
    "x_min, x_max = generated_data[0][:, 0].min() - 1, generated_data[0][:, 0].max() + 1\n",
    "y_min, y_max = generated_data[0][:, 1].min() - 1, generated_data[0][:, 1].max() + 1\n",
    "\n",
    "# グリッドの解像度\n",
    "num_points = 100\n",
    "X, Y = np.meshgrid(np.linspace(x_min, x_max, num_points),\n",
    "                   np.linspace(y_min, y_max, num_points))\n",
    "\n",
    "# KDEをグリッド上で評価\n",
    "# (2, num_points*num_points) の形状に変換してkdeに渡す\n",
    "Z = kde_generated_data(np.vstack([X.ravel(), Y.ravel()]))\n",
    "Z = Z.reshape(X.shape) # 元のグリッド形状に戻す\n",
    "\n",
    "# --- 2つの山の頂点を特定 (前回のコードから再利用) ---\n",
    "# 1. 最初のピーク（グローバル最大値）を見つける\n",
    "max_z_idx_flat = np.argmax(Z)\n",
    "row1, col1 = np.unravel_index(max_z_idx_flat, Z.shape)\n",
    "peak1_coords_2d = np.array([X[row1, col1], Y[row1, col1]])\n",
    "peak1_density = Z[row1, col1]\n",
    "\n",
    "# 2. 最初のピーク周辺をマスクして2番目のピークを見つける\n",
    "Z_masked = Z.copy()\n",
    "mask_radius = 4 # マスクする半径 (GMMの分散やモード間距離に応じて調整)\n",
    "\n",
    "distances_from_peak1 = np.sqrt((X - peak1_coords_2d[0])**2 + (Y - peak1_coords_2d[1])**2)\n",
    "Z_masked[distances_from_peak1 < mask_radius] = -1e10 # 負の大きな値に設定して最大値検索から除外\n",
    "\n",
    "max_z_masked_idx_flat = np.argmax(Z_masked)\n",
    "row2, col2 = np.unravel_index(max_z_masked_idx_flat, Z_masked.shape)\n",
    "peak2_coords_2d = np.array([X[row2, col2], Y[row2, col2]])\n",
    "peak2_density = Z[row2, col2] # マスク前のZから実際の密度を取得\n",
    "\n",
    "# --- 3次元空間における距離を計算 ---\n",
    "# ピークの3D座標を定義 (X, Y, Density)\n",
    "peak1_coords_3d = np.array([peak1_coords_2d[0], peak1_coords_2d[1], peak1_density])\n",
    "peak2_coords_3d = np.array([peak2_coords_2d[0], peak2_coords_2d[1], peak2_density])\n",
    "\n",
    "# 3Dユークリッド距離を計算\n",
    "distance_3d = np.linalg.norm(peak1_coords_3d - peak2_coords_3d)\n",
    "\n",
    "print(f\"最初のピークの座標: ({peak1_coords_3d[0]:.2f}, {peak1_coords_3d[1]:.2f}, 密度(z): {peak1_coords_3d[2]:.4f})\")\n",
    "print(f\"2番目のピークの座標: ({peak2_coords_3d[0]:.2f}, {peak2_coords_3d[1]:.2f}, 密度(z): {peak2_coords_3d[2]:.4f})\")\n",
    "print(f\"2D空間におけるピーク頂点間の距離: {np.linalg.norm(peak1_coords_2d - peak2_coords_2d):.2f}\")\n",
    "print(f\"3D空間におけるピーク頂点間の距離 (密度をz軸として): {distance_3d:.4f}\")\n",
    "\n",
    "# --- 3Dプロット ---\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# サーフェスプロット\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none', alpha=0.8)\n",
    "\n",
    "ax.scatter(peak1_coords_3d[0], peak1_coords_3d[1], peak1_coords_3d[2], color='red', s=100, label='Peak 1', zorder=10)\n",
    "ax.scatter(peak2_coords_3d[0], peak2_coords_3d[1], peak2_coords_3d[2], color='blue', s=100, label='Peak 2', zorder=10)\n",
    "\n",
    "# ラベルとタイトル\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "ax.set_zlabel('Density')\n",
    "ax.set_title('3D Kernel Density Estimate from Generated Data')\n",
    "\n",
    "# 視点の調整 (任意)\n",
    "ax.view_init(elev=30, azim=150) # 仰角と方位角\n",
    "\n",
    "# 保存\n",
    "# plt.savefig('kde_3d_generated_data_plot.png')\n",
    "# print(\"KDE_generated_dataに対する3Dの図示を 'kde_3d_generated_data_plot.png' として保存しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### それぞれのバッチで距離を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 距離をまとめるリスト\n",
    "distances = []\n",
    "\n",
    "for i in range(generated_data.shape[0]):\n",
    "    print(f\"generated_data[{i}].shape\", generated_data[i].shape) # (1000, 2)\n",
    "    from scipy.stats import gaussian_kde\n",
    "    target_data = generated_data[i] # 各バッチのデータを取得\n",
    "    kde_generated_data = gaussian_kde(target_data.T)\n",
    "\n",
    "    # --- 評価グリッドの定義 ---\n",
    "    # generated_data[i] の範囲に基づいてグリッドを生成\n",
    "    x_min, x_max = target_data[:, 0].min() - 1, target_data[:, 0].max() + 1\n",
    "    y_min, y_max = target_data[:, 1].min() - 1, target_data[:, 1].max() + 1\n",
    "\n",
    "    # グリッドの解像度\n",
    "    num_points = 100\n",
    "    X, Y = np.meshgrid(np.linspace(x_min, x_max, num_points),\n",
    "                      np.linspace(y_min, y_max, num_points))\n",
    "\n",
    "    # KDEをグリッド上で評価\n",
    "    # (2, num_points*num_points) の形状に変換してkdeに渡す\n",
    "    Z = kde_generated_data(np.vstack([X.ravel(), Y.ravel()]))\n",
    "    Z = Z.reshape(X.shape) # 元のグリッド形状に戻す\n",
    "\n",
    "    # --- 2つの山の頂点を特定 (前回のコードから再利用) ---\n",
    "    # 1. 最初のピーク（グローバル最大値）を見つける\n",
    "    max_z_idx_flat = np.argmax(Z)\n",
    "    row1, col1 = np.unravel_index(max_z_idx_flat, Z.shape)\n",
    "    peak1_coords_2d = np.array([X[row1, col1], Y[row1, col1]])\n",
    "    peak1_density = Z[row1, col1]\n",
    "\n",
    "    # 2. 最初のピーク周辺をマスクして2番目のピークを見つける\n",
    "    Z_masked = Z.copy()\n",
    "    mask_radius = 4 # マスクする半径 (GMMの分散やモード間距離に応じて調整)\n",
    "\n",
    "    distances_from_peak1 = np.sqrt((X - peak1_coords_2d[0])**2 + (Y - peak1_coords_2d[1])**2)\n",
    "    Z_masked[distances_from_peak1 < mask_radius] = -1e10 # 負の大きな値に設定して最大値検索から除外\n",
    "\n",
    "    max_z_masked_idx_flat = np.argmax(Z_masked)\n",
    "    row2, col2 = np.unravel_index(max_z_masked_idx_flat, Z_masked.shape)\n",
    "    peak2_coords_2d = np.array([X[row2, col2], Y[row2, col2]])\n",
    "    peak2_density = Z[row2, col2] # マスク前のZから実際の密度を取得\n",
    "\n",
    "    # --- 3次元空間における距離を計算 ---\n",
    "    # ピークの3D座標を定義 (X, Y, Density)\n",
    "    peak1_coords_3d = np.array([peak1_coords_2d[0], peak1_coords_2d[1], peak1_density])\n",
    "    peak2_coords_3d = np.array([peak2_coords_2d[0], peak2_coords_2d[1], peak2_density])\n",
    "\n",
    "    # 3Dユークリッド距離を計算\n",
    "    distance_3d = np.linalg.norm(peak1_coords_3d - peak2_coords_3d)\n",
    "\n",
    "    print(f\"最初のピークの座標: ({peak1_coords_3d[0]:.2f}, {peak1_coords_3d[1]:.2f}, 密度(z): {peak1_coords_3d[2]:.4f})\")\n",
    "    print(f\"2番目のピークの座標: ({peak2_coords_3d[0]:.2f}, {peak2_coords_3d[1]:.2f}, 密度(z): {peak2_coords_3d[2]:.4f})\")\n",
    "    print(f\"2D空間におけるピーク頂点間の距離: {np.linalg.norm(peak1_coords_2d - peak2_coords_2d):.2f}\")\n",
    "    print(f\"3D空間におけるピーク頂点間の距離 (密度をz軸として): {distance_3d:.4f}\")\n",
    "\n",
    "    # 距離をリストに追加\n",
    "    distances.append(distance_3d)\n",
    "\n",
    "    # # --- 3Dプロット ---\n",
    "    # fig = plt.figure(figsize=(10, 8))\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # # サーフェスプロット\n",
    "    # ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none', alpha=0.8)\n",
    "\n",
    "    # ax.scatter(peak1_coords_3d[0], peak1_coords_3d[1], peak1_coords_3d[2], color='red', s=100, label='Peak 1', zorder=10)\n",
    "    # ax.scatter(peak2_coords_3d[0], peak2_coords_3d[1], peak2_coords_3d[2], color='blue', s=100, label='Peak 2', zorder=10)\n",
    "\n",
    "    # # ラベルとタイトル\n",
    "    # ax.set_xlabel('Dimension 1')\n",
    "    # ax.set_ylabel('Dimension 2')\n",
    "    # ax.set_zlabel('Density')\n",
    "    # ax.set_title('3D Kernel Density Estimate from Generated Data')\n",
    "\n",
    "    # # 視点の調整 (任意)\n",
    "    # ax.view_init(elev=30, azim=150) # 仰角と方位角\n",
    "\n",
    "    # 保存\n",
    "    # plt.savefig('kde_3d_generated_data_plot.png')\n",
    "    # print(\"KDE_generated_dataに対する3Dの図示を 'kde_3d_generated_data_plot.png' として保存しました。\")\n",
    "\n",
    "print(\"距離算出完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distancesの平均と標準偏差を計算\n",
    "mean_distance = np.mean(distances)\n",
    "std_distance = np.std(distances)\n",
    "print(f\"ブートストラップサンプル間の3D空間におけるピーク頂点間の距離の平均: {mean_distance:.4f}\")\n",
    "print(f\"ブートストラップサンプル間の3D空間におけるピーク頂点間の距離の標準偏差: {std_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算出した距離の分布\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(distances, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Distances Between Peaks')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
