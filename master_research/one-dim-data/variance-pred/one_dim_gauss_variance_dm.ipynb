{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次元正規分布 分散推定 BS vs DM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mカーネルを起動できませんでした。 \n",
      "\u001b[1;31mJupyter Server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/home/simada/.local/bin/jupyter-notebook\", line 5, in <module>\n",
      "\u001b[1;31m    from notebook.app import main\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/notebook/app.py\", line 20, in <module>\n",
      "\u001b[1;31m    from jupyterlab.commands import (  # type:ignore[import-untyped]\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/jupyterlab/__init__.py\", line 8, in <module>\n",
      "\u001b[1;31m    from .handlers.announcements import (\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/jupyterlab/handlers/announcements.py\", line 15, in <module>\n",
      "\u001b[1;31m    from jupyterlab_server.translation_utils import translator\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/jupyterlab_server/__init__.py\", line 6, in <module>\n",
      "\u001b[1;31m    from .app import LabServerApp\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/jupyterlab_server/app.py\", line 15, in <module>\n",
      "\u001b[1;31m    from .handlers import LabConfig, add_handlers\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/jupyterlab_server/handlers.py\", line 21, in <module>\n",
      "\u001b[1;31m    from .listings_handler import ListingsHandler, fetch_listings\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/jupyterlab_server/listings_handler.py\", line 10, in <module>\n",
      "\u001b[1;31m    import requests\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/requests/__init__.py\", line 43, in <module>\n",
      "\u001b[1;31m    import urllib3\n",
      "\u001b[1;31m  File \"/home/simada/.local/lib/python3.9/site-packages/urllib3/__init__.py\", line 42, in <module>\n",
      "\u001b[1;31m    raise ImportError(\n",
      "\u001b[1;31mImportError: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'OpenSSL 1.0.2k-fips  26 Jan 2017'. See: https://github.com/urllib3/urllib3/issues/2168. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "start_time = time.time() # 計測開始\n",
    "\n",
    "# Pytorchの組み込み演算により効率的に計算\n",
    "# 高次元データ用のtorch.arrangeやtorch.expを活用してコードを簡潔に\n",
    "\n",
    "# 時間埋め込み（正弦波位置エンコーディング）\n",
    "def pos_encoding(timesteps, output_dim, device='cpu'):\n",
    "    position = timesteps.view(-1, 1).float()  # 必要に応じて型変換\n",
    "    div_term = torch.exp(torch.arange(0, output_dim, 2, device=device, dtype=torch.float32) * \n",
    "                         (-np.log(10000.0) / output_dim))\n",
    "    sinusoid = torch.cat([torch.sin(position * div_term), torch.cos(position * div_term)], dim=1)\n",
    "    return sinusoid\n",
    "\n",
    "# Dropoutの導入: 過学習を防ぐために、各隠れ層にnn.Dropoutを追加。\n",
    "# Batch Normalizationの導入: 学習を安定させるためにnn.BatchNorm1dを適用。\n",
    "# 活性化関数の選択: F.reluの代わりにnn.LeakyReLUやnn.ELUを試すことで、勾配消失問題に対応。\n",
    "\n",
    "# 拡散モデル\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, time_embed_dim=16):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.time_embed_dim = time_embed_dim  # time_embed_dimをインスタンス変数として初期化\n",
    "        self.fc1 = nn.Linear(1 + time_embed_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # 時間埋め込み\n",
    "        t_embed = pos_encoding(t, self.time_embed_dim, x.device)\n",
    "        x_t = torch.cat([x, t_embed], dim=1)  # 時間情報と入力データを結合\n",
    "        x_t = F.relu(self.fc1(x_t))\n",
    "        x_t = F.relu(self.fc2(x_t))\n",
    "        return self.fc3(x_t)\n",
    "\n",
    "# 拡散プロセス\n",
    "class Diffuser:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02, device='cpu'):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.device = device\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def add_noise(self, x_0, t):\n",
    "        t_idx = t - 1 # alphas[0] is for t=1\n",
    "        alpha_bar = self.alpha_bars[t_idx].view(-1, 1)  # (N, 1)\n",
    "        noise = torch.randn_like(x_0, device=self.device)\n",
    "        x_t = torch.sqrt(alpha_bar) * x_0 + torch.sqrt(1 - alpha_bar) * noise\n",
    "        return x_t, noise\n",
    "\n",
    "    def denoise(self, model, x, t):\n",
    "        T = self.num_timesteps\n",
    "        assert (t >= 1).all() and (t <= T).all()\n",
    "        \n",
    "        t_idx = t - 1 # alphas[0] is for t=1\n",
    "        alpha = self.alphas[t_idx].view(-1, 1)\n",
    "        alpha_bar = self.alpha_bars[t_idx].view(-1, 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            eps = model(x, t)\n",
    "\n",
    "        noise = torch.randn_like(x, device=self.device)\n",
    "        noise[t == 1] = 0  # no noise at t=1\n",
    "\n",
    "        mu = (x - (1 - alpha) / torch.sqrt(1 - alpha_bar) * eps) / torch.sqrt(alpha)\n",
    "\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "\n",
    "# ハイパーパラメータ\n",
    "num_timesteps = 1000 # 拡散ステップ数\n",
    "epochs = 20          # 学習エポック数\n",
    "lr = 1e-3            # 学習率\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# シード値の固定\n",
    "np.random.seed(42)\n",
    "\n",
    "# サンプリング\n",
    "iter = 1 #学習元データの数\n",
    "# シード値の生成\n",
    "random_seed = np.random.randint(0, 10000, iter)\n",
    "\n",
    "# モデルとデータを管理する辞書\n",
    "models = {}\n",
    "datas = {}\n",
    "\n",
    "for (i, seed) in enumerate(random_seed):\n",
    "    print(\"-\"*50)\n",
    "    print(\"#\"*50)\n",
    "    print(f\"Data_Set_{i+1}, Seed: {seed}\")\n",
    "\n",
    "    # モデルの初期化\n",
    "    time_embed_dim = 16\n",
    "    model = DiffusionModel(time_embed_dim=time_embed_dim).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    diffuser = Diffuser(num_timesteps=num_timesteps, device=device)\n",
    "\n",
    "    # 学習データ(ガウスノイズ)\n",
    "    np.random.seed(seed)\n",
    "    data = np.random.randn(50)  # shape: (50,)\n",
    "    # scaler = StandardScaler()\n",
    "    # data = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "    print(\"Train Data Mean:\", data.mean())\n",
    "    print(\"Train Data Std:\", data.std())\n",
    "    print(\"Train Data Shape:\", data.shape)\n",
    "    train_data = torch.tensor(data, dtype=torch.float32).view(-1, 1).to(device)  # shape: (10, 1)\n",
    "\n",
    "    # データローダー作成\n",
    "    batch_size = 10\n",
    "    dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 学習\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0.0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x = batch.to(device)\n",
    "            t = torch.randint(1, num_timesteps + 1, (len(x),), device=device)\n",
    "\n",
    "            x_noisy, noise = diffuser.add_noise(x, t)\n",
    "            noise_pred = model(x_noisy, t)\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "        avg_loss = loss_sum / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        # 5の倍数エポックで損失を表示\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")\n",
    "    # 辞書に保存\n",
    "    models[f\"model_{i+1}\"] = model\n",
    "    datas[f\"seed_{seed}\"] = data\n",
    "    print(\"学習終了\")\n",
    "    end_time = time.time() # 計測終了\n",
    "    print('\\n')\n",
    "    print(f\"学習時間: {end_time - start_time:.2f}秒\")\n",
    "\n",
    "    # 学習曲線のプロット\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Trained By data_by_seed_{}'.format(seed))\n",
    "    plt.show()\n",
    "    print('\\n')\n",
    "    print(\"#\"*50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "\n",
    "## サンプリング\n",
    "\n",
    "# 結果の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # 生成に使用するモデルを選択\n",
    "# model_key = \"model_1\"  # 例として \"dataset_0\" のモデルを使用\n",
    "# selected_model = models[model_key]  # 辞書からモデルを取得\n",
    "\n",
    "# 拡散モデルのサンプリング関数\n",
    "def generate_samples(model, n=50, B=1000, device='cpu'):\n",
    "    # n: 1データセットあたりのサンプル数\n",
    "    # B: データセットの数\n",
    "    model.eval()  # 評価モードに設定\n",
    "    with torch.no_grad():\n",
    "        new_sample_list = []\n",
    "        for _ in range(B):\n",
    "            torch.manual_seed(np.random.randint(0, 10000)) # シード値の固定\n",
    "            samples = torch.randn((n, 1), device=device) # デノイズ前の乱数データ\n",
    "            for t in range(num_timesteps, 0, -1): \n",
    "                t_tensor = torch.tensor([t] * len(samples), device=device) # 時刻tのテンソル\n",
    "                samples = diffuser.denoise(model, samples, t_tensor) # ノイズ除去\n",
    "            samples = samples.view(n).cpu().numpy() # numpy配列に変換\n",
    "            new_sample_list.append(samples) # サンプルをリストに追加\n",
    "    return new_sample_list\n",
    "\n",
    "generated_data_list = []\n",
    "\n",
    "for seed, data, model_key, selected_model in zip(datas.keys(), datas.values(), models.keys(), models.values()):\n",
    "    print(\"-\"*50)\n",
    "    print(\"#\"*50)\n",
    "    print(f\"Seed: {seed.split('_')[-1]}\")\n",
    "    print(\"サンプリング開始\")\n",
    "\n",
    "    start_time = time.time() # 計測開始\n",
    "    generated_data = generate_samples(selected_model, n=50, B=1000, device=device) # サンプリング実行\n",
    "    generated_data_list.append(generated_data) # サンプルをリストに追加\n",
    "    end_time = time.time() # 計測終了\n",
    "    print(\"サンプリング終了\")\n",
    "\n",
    "    print(f\"サンプリング時間: {end_time - start_time:.2f}秒\")\n",
    "    print(f\"サンプリング時間: {(end_time - start_time)//60}分 {(end_time - start_time)%60}秒\")\n",
    "\n",
    "    # サンプルされたデータの保存\n",
    "    torch.save(generated_data, f\"master_research/saved_data/sampled_data/sampled_data_{seed.split('_')[-1]}_epoch_{epochs}.pth\")\n",
    "    print(\"#\"*50)\n",
    "\n",
    "# # 学習済みモデルと学習乱数データの保存と読み込み\n",
    "# torch.save(models, 'models_dm_epo30.pth')　# モデルの保存\n",
    "# torch.save(datas, 'sample_datas_dm_epo30.pth')　# 学習乱数データの保存\n",
    "# models = torch.load('models_dm_epo30.pth')　# モデルの読み込み\n",
    "# datas = torch.load('sample_datas_dm_epo30.pth') # 学習乱数データの読み込み\n",
    "\n",
    "# # サンプルされたの保存\n",
    "# torch.save(datas, 'sample_datas_dm_epo30.pth')　# データの保存\n",
    "# datas = torch.load('sample_datas_dm_epo30.pth') # データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 学習済みモデルと学習乱数データの読み込み\n",
    "models = torch.load('master_research/saved_data/models/models_dm_epo30.pth')  # モデルの読み込み\n",
    "datas = torch.load('master_research/saved_data/datas/sample_datas_dm_epo30.pth')  # 学習乱数データの読み込み\n",
    "\n",
    "# サンプルされたデータの読み込み seedとepochを指定\n",
    "generated_data = torch.load('master_research/saved_data/generated_data/generated_data_1_epoch_20.pth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "\n",
    "## 学習データの可視化\n",
    "for seed, data in zip(datas.keys(), datas.values()):\n",
    "    plt.hist(data, bins=20, alpha=0.7, color='blue', edgecolor='black', label=f\"Data from seed_{seed.split('_')[-1]}\" ) # 学習データのヒストグラムのプロット\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Training Data from seed_{seed.split('_')[-1]}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## サンプリングデータの可視化\n",
    "generated_data_var_list = []\n",
    "# 生成データの＊＊(ある統計量)を求める\n",
    "# ヒストグラムプロット\n",
    "for generated_data, seed in zip(generated_data_list, datas.keys()):\n",
    "    generated_data_var = np.var(generated_data, axis=1) # 生成データそれぞれ分散を求める\n",
    "    generated_data_var_list.append(generated_data_var) # 平均をリストに追加\n",
    "    print(\"generated_data_mean Shape:\",generated_data_var.shape) # サイズの確認\n",
    "    # 平均のヒストグラムのプロット\n",
    "    plt.hist(generated_data_var, bins=20, alpha=0.7, color='yellow', edgecolor='black', label=f\"Generated from {seed}\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Generated Samples Variance from {seed}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
